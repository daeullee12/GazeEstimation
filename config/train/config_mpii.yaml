---
train:

    params:
        batch_size: 64  # Reduce batch size to help with GPU memory allocation
        epoch: 20
        lr: 0.00005  # Learning rate
        decay: 0.5 # Weight decay factor
        decay_step: 5  # Step size for learning rate decay
        warmup: false
        # grad_accum_steps: 4  # Re-enable gradient accumulation steps

    save:
        metapath: "./save"
        folder: mpii
        model_name: leave_fine
        step: 10

    data:
        image: "./MPIIGaze_out/Image"
        label: "./MPIIGaze_out/Label"
        header: True
        name: mpii
        isFolder: True  # Set this to True
        
    pretrain:
        enable: true
        path: "./save_mod/mpii/mobilenet_v2/leave_80_final.pth"  # Path to the pre-trained model
        device: 0

    device: 0

    reader: reader

    freeze_transformer: false  # Set this to true to freeze transformer layers

    # backbone: mobilenet_v2  # Use MobileNetV2 as the backbone
    backbone: efficientnet-b0
    # backbone: resnet18

    pretrained: True  # Set this to True to use the pretrained model

# dropout = 0
# dim_feed = 512
